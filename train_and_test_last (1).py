# -*- coding: utf-8 -*-
"""train_and_test_last

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oGVzox8cvpYiPr0AydbFjiBv3rwCIDTA
"""

import tensorflow as tf
import json
import numpy as np
import os
import sys
import time
import pandas as pd
import cv2
from keras.preprocessing import sequence
from pathlib import Path
from tensorflow.python.framework.ops import disable_eager_execution
tf.config.run_functions_eagerly(False)

'''
This takes the CNN features of a video frames and passes it through Back to Back LSTMs(Sequence to Sequence
Model) to generate the Caption for the Video
 path_prj - Project directory.
 feat_dir - Subdirectory containing the CNN features .. absolute path /path_prj/feat_dir/
 cnn_feat_dim - Dimension of the feature vector from CNN for each image frame 
 video_steps -  No of image frames from each video. 
 out_steps  - Sequence length for the text caption. The output text sequence would be contained in 2o words.
 learning rate - training hyper parameter
 epoch     - Traing epochs
 model_path - Absolute Path to save the model 
 mode - train/inference 
'''

class VideoCaptioning:
    
    
    def __init__(self,path_prj=r"/content/drive/MyDrive",caption_file="train_val_videodatainfo.json",feat_dir="final_feat",
                 cnn_feat_dim=2088,h_dim=512,
                 lstm_steps=80,video_steps=80,
                 out_steps=72, frame_step=80,
                 batch_size=512,learning_rate=1e-3,
                 epochs=20,model_path=None,
                 mode="train"):
# قمنا بتعريف الباني البارمتر الأول هو عبارة عن مسار المشروع البارمتر الثاني هو عبارة عن ملف الجيسون الخاص بالداتا سيت والذي يحوي على رقم المقطع الفديو ووصفة 
# lstm الثالث يعبر عن ملف الفتشرات الذي قمنا باستخراجه من المرحلة السابقة الرابع يعبرعن بعد مصفوفة الفتشرات الثاني و البارمتر الخامس يعبر عن سعة خلية ال  
# encoding التي سوف يتم بناءها في الطبقة الأولى و الثانية من مرحلة ال lstm  البارمتر السادس يعبر عن عدد خلايا 
# 80x2088 البارمتر السابع والذي يعبر عن ان مصفوفة الفتشرات سوف يتم تقسيمها الى 80 قسم بما ان ابعادها         
# encoding وسوف يتم اعطاء كل شعاع 2088 الى خلية من الخلايا ال 80 في الطبقة الأولى من مرحلة ال  
# decoding التي سوف يتم بناءها في الطبقتين الأولى والثانية من مرحلة ال lstm البارمتر الثامن بعبر عن عدد خلايا ال         
# البارمتر التاسع  بعبر عن عدد الصور التي تم اخذها من كل مقطع فديو 
#  batch  البارمتر العاشر يعبر عن قيمة ال   
#  البارمتر ال 11 يعبر عن معدل التعلم 
#  ال 12 يعبر عن عدد التكرارت 
#  ال 13 يعبر عن مسار النموذج 
#  يكون للاختبار  test يكون للتدريب و اذا  train   ال 15 يعبر عن هل اريد هذا الكود للتدريب او للاختيار فإذا كان      
# القيم التي تم اسنادها الى البارمترات هي عبارة عن قيم افتراضية         
        self.dim_image = cnn_feat_dim  # عمليات اسناد فقط
        self.dim_hidden = h_dim
        self.batch_size = batch_size
        self.lstm_steps = lstm_steps
        self.video_lstm_step=video_steps
        self.caption_lstm_step=out_steps
        self.path_prj = Path(path_prj)
        self.mode = mode
        if mode == 'train':
            self.train_text_path = self.path_prj/caption_file  # للداتا سيت  json مسار ملف ال  
            self.train_feat_path = self.path_prj/feat_dir  # مسار ملف الفتشرات 
        else:
            self.test_text_path = self.path_prj / caption_file  # هنا للاختبار ونفس الشرح السابق
            self.test_feat_path = self.path_prj / feat_dir
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.frame_step = frame_step
        self.model_path = model_path

    def build_model(self):    # تابع من اجل بناء النموذج 
        tf.compat.v1.disable_v2_behavior()     # هذه التعليمة  لأن كولاب يعمل على نسخة 2:5:0 ونحن نعمل على نسخة 1:9:0
        # Defining the weights associated with the Network
        with tf.device('/gpu:0'): # gpu هذه التعليمة من اجل استخدام ال 
            self.word_emb = tf.Variable(tf.random.uniform([self.n_words, self.dim_hidden], -0.1, 0.1), name='word_emb')
            # قمنا يتعريف متحول والذي يعبر عن المتغيرات في طبقة التضمين                                                                  
        self.lstm1 = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.dim_hidden, state_is_tuple=False)
        # الأولى  lstm  قمنا ببناء طبقة ال 
        self.lstm2 = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.dim_hidden, state_is_tuple=False)
        # الثانية  lstm  قمنا بتعريف طيقة ال 
        self.encode_W = tf.Variable( tf.random.uniform([self.dim_image,self.dim_hidden], -0.1, 0.1), name='encode_W')
        #      80 x قمنا بتعريف هذا المتحول والذي سوف يعمل على  تقليل بعد مصفوفة الفديو من  2088
        #      80  x الى  512
        #lstm لكي يصبح بنفس بعد سعة خلية ال 
        self.encode_b = tf.Variable( tf.zeros([self.dim_hidden]), name='encode_b')
        # نفس عمل المتحول السابق 
        self.word_emb_W = tf.Variable(tf.random.uniform([self.dim_hidden,self.n_words], -0.1,0.1), name='word_emb_W')
        self.word_emb_b = tf.Variable(tf.zeros([self.n_words]), name='word_emb_b')
        # dense الثانية و طبقة ال  lstm  قمنا بتعريف هذين المتحولين واعطاء قيم عشوائية لهم يكون موقعن بين طبقة ال 
        
        # Placeholders 
        # sess  هي عبارة عن ثوابت يتم اخدها عبر الجلسة   Placeholder
        video = tf.compat.v1.placeholder(tf.float32, [self.batch_size, self.video_lstm_step, self.dim_image])
        #  هذا الثابت عبارة عن المصفوفة التي سوف يتم تخزين فيها جميع مصفوفات الفتشرات 
        # والتي عددها بعدد الباتش سايز في كل تكرار 
        video_mask = tf.compat.v1.placeholder(tf.float32, [self.batch_size, self.video_lstm_step])
         # هذا الثابت سوف نستخدمة من اجل تقسيم مصفوفة الفتشرات للفديو الى 80 قسم من اجل ان تعالج كل خلية لستم ال 80 قسم  
        caption = tf.compat.v1.placeholder(tf.int32, [self.batch_size, self.caption_lstm_step+1])
        # batch لهذا الثابت يمثل الجمل او الوصف لكل جمل ال 
        caption_mask = tf.compat.v1.placeholder(tf.float32, [self.batch_size, self.caption_lstm_step+1])
        # هذه عبارة عن مصفوفة من الواحدات والأصفار الواحدات تكون في اول المصفوفة لأنها تعبر عن عدد كلمات وصف الفديو مثلا انا عندي 20 واحد بالتالي وصف الفديو له 20 كلمة والباقي اصفار اي باد يعني حشو 
        video_flat = tf.reshape(video, [-1, self.dim_image])# 512*80x2088 هذه التعليمة تحول ابعاد الفديو الى 
        image_emb = tf.compat.v1.nn.xw_plus_b( video_flat, self.encode_W,self.encode_b )   # 40960 x 2088      
        image_emb = tf.reshape(image_emb, [self.batch_size, self.lstm_steps, self.dim_hidden])
        # هنا تم انقاط بعد الفديو من 2088 الى 512 
        # حيث تم ضرب مصفوفة الفديو بالوزن وجمع الانحياز 
        #  512 x 80 x حيث اصبح 512
        state1 = tf.zeros([self.batch_size, self.lstm1.state_size])
        state2 = tf.zeros([self.batch_size, self.lstm2.state_size])
        padding = tf.zeros([self.batch_size, self.dim_hidden])
        # لكل خلايا الطبقة الأولى والثانية قيم صفرية وال اذا لم يكن هناك دخل ايضا سنضع اصفار  hidden state  قمنا بإعطاء 
        #  لأول 80 خلية في الطبقة الثانية  encoding  كما في مرحلة ال 
        # decoding وخلايا  الطبقة الأولى ال 72  في مرحلة ال 
        probs = []  # مصفوفة لنخزين الاحتمالات لكل تابع softmax
        loss = 0.0    # قيمة الخطأ صفر 

        #  Encoding Stage   
        #في هذه المرحلة قسمنا مصفوفة المقطع الفيديو الجديدة الى 80 قسم وقمنا في كل تكرار بمعالجة قسم حيث ان في كل تكرار سوف تكون خلية من ال 80 خلية تعالج قسم  
        for i in range(0, self.video_lstm_step):
            if i > 0:
                tf.compat.v1.get_variable_scope().reuse_variables()

            with tf.compat.v1.variable_scope("LSTM1"):
                output1, state1 = self.lstm1(image_emb[:,i,:], state1) #hidden state و ال   i هنا تم إعطاء القسم 

            with tf.compat.v1.variable_scope("LSTM2"):
                output2, state2 = self.lstm2(tf.concat([padding, output1],1), state2) #من الطبقة الثانية والتي سوف تأخذ دخل كما قلنا صفري وخرج الخلية في الطبقة الأولى التي بنفس دليلها i هنا نحن اصبحنا في الخلية   
        # وهنا عندما تتم ال 80 تكرار نكون قد عالجنا جميع مصفوفات الفتشرات لكل فديوهات بعدد الباتش 
        #  Decoding Stage  to generate Captions 
        #  في هذه المرحلة سوف نقوم ب 72 تكرار لان اطول جملة في الوصف تحتوي على 72 كلمة 
        for i in range(0, self.caption_lstm_step):

            with tf.device("/gpu:0"): # نحن هنا نقوم باخذ تضمين الكلمة الأولى في كل باتش لأننا نقوم بتحويل الكلمة الى ارقام وهذا يسمى التضمين 
            # لكي يصبح النموذج قادر على معالجتها   
                current_embed = tf.compat.v1.nn.embedding_lookup(self.word_emb, caption[:, i])

            tf.compat.v1.get_variable_scope().reuse_variables()
 
            with tf.compat.v1.variable_scope("LSTM1"):  #hidden state هنا نحن في الطبقة الأولى في الخلية الاولى من 72 خلية حيث سيكون دخلها كما ذكرنا سابقاً اصفار و 
                output1, state1 = self.lstm1(padding, state1)

            with tf.compat.v1.variable_scope("LSTM2"): # و خرج الخلية الأولى من الطبقة السابقة  eos هنا نحن في الخلية الأولى من الطبقة الثانية سوف يكون الدخل هو عبارة عن الكلمة المضمنة الأولى في كل باتش والتي سوف تكون عبارة عن 
                output2, state2 = self.lstm2(tf.concat([current_embed, output1],1), state2) #hidden state وال  

            labels = tf.expand_dims(caption[:, i+1], 1) #  هنا تم توسعة الأبعاد بمقدار 1 للمصفوفة التي هي عبارة عن الكلمات من 0 الى الموقع الحالي
            indices = tf.expand_dims(tf.range(0, self.batch_size, 1), 1)#   1 هنا تم توسعة الأبعاد بمقدار  
            # حيث المصفوفة تعبر عن قيم الباتش من 0 الى 512
            concated = tf.concat([indices, labels],1)# تم دمج المصفوفتين معاً 
            onehot_labels = tf.compat.v1.sparse_to_dense(concated, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)
            #  في هذه المرحلة تم تحويل المصفوفة السابقة الى واحدات وأصفار ببعد الباتش ضرب عدد الكلمات 
            logit_words = tf.compat.v1.nn.xw_plus_b(output2, self.word_emb_W, self.word_emb_b)
           # dense هنا قمنا بضرب خرج الخلية في الطبقة الثانية ببارمترات طبقة ال 
        # Computing the loss     
            cross_entropy = tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=logit_words,labels=onehot_labels)
            #cross entropy ثم حساب قيمة الخطأ من خلال تابع ال خطأ  softmax  هنا تم تطبيق تابع ال 
            cross_entropy = cross_entropy * caption_mask[:,i]  # نضربه بالماسك الذي هو عبارة عن صفر او واحد بالتالي اذا كان عدد كلمات الجملة 20 بالتالي نحن ال 52 خطأ التي ظهر لدينا لا نريده بالتالي نصفر قيمته
            probs.append(logit_words)

            current_loss = tf.math.reduce_sum(cross_entropy)/self.batch_size #  هنا لكل مقطع فديو وجملته سيكون لها خطأ ونحن لدينا 512 حسب الباتش لذلك نجمع هذه الأخطاء ونقسمها على عددها ويكون قيمة الخطأ النهائي لكل الباتش  ولكن فقط لتكرار واحد أو فقط لخلية واحدة 
            loss = loss + current_loss # هنا يتم جمع هذا الخطأ في كل خلية لنصل الى الخطأ النهائي للباتش بالنسبة للجمل 
        with tf.compat.v1.variable_scope(tf.compat.v1.get_variable_scope(),reuse=tf.compat.v1.AUTO_REUSE):
            train_op = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(loss) #حيث يمرر له فقط معدل التعلم ونقول له صغر الخطأ ونمرر له الخطأ  Adam optimizer  وهو     optimizer  هنا بعد أن قمنا بحساب الخطأ الكلي للباتش سوف نعمل على تخفيضة اي تطبيق    

        return loss, video, video_mask, caption, caption_mask, probs,train_op  # وهنا نكون قد انتهينا من بناء النموذج 


    def build_generator(self):
        tf.compat.v1.disable_v2_behavior()
        with tf.device('/gpu:0'):
            self.word_emb = tf.Variable(tf.random.uniform([self.n_words, self.dim_hidden], -0.1, 0.1), name='word_emb')

         
        self.lstm1 = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.dim_hidden, state_is_tuple=False)
        self.lstm2 = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(self.dim_hidden, state_is_tuple=False)

        self.encode_W = tf.Variable( tf.random.uniform([self.dim_image,self.dim_hidden], -0.1, 0.1), name='encode_W')
        self.encode_b = tf.Variable( tf.zeros([self.dim_hidden]), name='encode_b')
        tf.compat.v1.disable_eager_execution()
        self.word_emb_W = tf.Variable(tf.random.uniform([self.dim_hidden,self.n_words], -0.1,0.1), name='word_emb_W')
        self.word_emb_b = tf.Variable(tf.zeros([self.n_words]), name='word_emb_b')
        video = tf.compat.v1.placeholder(tf.float32, [1, self.video_lstm_step, self.dim_image])
        video_mask = tf.compat.v1.placeholder(tf.float32, [1, self.video_lstm_step])

        video_flat = tf.reshape(video, [-1, self.dim_image])
        image_emb = tf.compat.v1.nn.xw_plus_b(video_flat, self.encode_W, self.encode_b)  

        image_emb = tf.reshape(image_emb, [1, self.video_lstm_step, self.dim_hidden])   

        state1 = tf.zeros([1, self.lstm1.state_size])
        state2 = tf.zeros([1, self.lstm2.state_size])
        padding = tf.zeros([1, self.dim_hidden])

        generated_words = []

        probs = []
        embeds = []

        for i in range(0, self.video_lstm_step):
            if i > 0:
                tf.compat.v1.get_variable_scope().reuse_variables()

            with tf.compat.v1.variable_scope("LSTM1"):
                output1, state1 = self.lstm1(image_emb[:, i, :], state1)

            with tf.compat.v1.variable_scope("LSTM2"):
                output2, state2 = self.lstm2(tf.concat([padding, output1],1), state2)

        for i in range(0, self.caption_lstm_step):
            tf.compat.v1.get_variable_scope().reuse_variables()

            if i == 0:
                with tf.device('/gpu:0'):
                    current_embed = tf.compat.v1.nn.embedding_lookup(self.word_emb, tf.ones([1], dtype=tf.int64))

            with tf.compat.v1.variable_scope("LSTM1"):
                output1, state1 = self.lstm1(padding, state1)

            with tf.compat.v1.variable_scope("LSTM2"):
                output2, state2 = self.lstm2(tf.concat([current_embed, output1],1), state2)

            logit_words = tf.compat.v1.nn.xw_plus_b( output2, self.word_emb_W, self.word_emb_b)
            max_prob_index = tf.argmax(logit_words, 1)[0]#  الى هنا سيكون نفس الشرح السابق ولكن هنا سوف يتولد كل كلمة في المفردات مع احتمالية ان تظهر في هذا  الموقع بالتالي سوف نأخذ الكلمة ذات الاحتمالية الأكبر 
            generated_words.append(max_prob_index)
            probs.append(logit_words) # احتمالية كل الكلمات في المفردات في كل خلية أو في كل تكرار تضاف الى هذه القائمة

            with tf.device("/gpu:0"):
                current_embed = tf.compat.v1.nn.embedding_lookup(self.word_emb, max_prob_index)
                current_embed = tf.expand_dims(current_embed, 0)# وهنا سنأخذ تضمين هذه الكلمة

            embeds.append(current_embed)# وفي هذه القائمة سوف يكون فيها تضمين الكلمات 72 التي سوف يتم اخذها في كامل المراحل

        return video, video_mask, generated_words, probs, embeds


    def get_data(self):
        
        with open(r"/content/drive/MyDrive/train_val_videodatainfo.json") as f:
             vdi = json.loads(f.read()) # فقط في هذا التابع قمنا بفتح ملف الجيسون وقمنا بأخذ العبارات والتي هي وصف للفديوهات 
             data=vdi["sentences"]
        
        return data
    
        
    def create_word_dict(self,sentence_iterator, word_count_threshold=5):
        
        word_counts = {} # في هذا التابع سنقوم ببناء قاموسين القاموس الأول سوف نعطيه الكلمة وسوف يعطينا دليلها والثاني بالعكس 
        sent_cnt = 0
        #  هنا سوف نمر على كامل الجمل في 7010 مقاطع فديو ويوجد 20 جملة طبيعية لكل فديو بالتالي لدينا 140200 جملة سوف نأخذ كلماتن ونضعن في القاموس 
        for sent in sentence_iterator:
            sent_cnt += 1 # تمثل عدد الجمل الكلي 140200
            for w in sent.lower().split(' '): # هنا كل جملة يتم تقسيمها الى كلاماتها وتصفير حالتها حيث بين كل كلمتين يوجد فراغ   
               word_counts[w] = word_counts.get(w, 0) + 1 #  هنا نعد عدد مرات تكرار كل كلمة 
        vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold and w != "a" and w.isalpha()]
        #لأنه اكبر تكرار له في الداتا بالتالي سوف يهيمن على النتائج وقمنا بحذف الأرقام  a  المفردات هي عبارة عن الكلمات التي تكرارها اكبر من العتبة ونحن وضعنا العتبة 0 و الكلمة ليست 
        idx2word = {}
        idx2word[0] = '<pad>'
        idx2word[1] = '<bos>'
        idx2word[2] = '<eos>'
        idx2word[3] = '<unk>'
        # قمنا بإضافة الكلمات الأربعة السابقة الى المفردات والتي تعبر عن  بداية الجملة و نهايتها وال باد تعبر عن انه لايوجد كلمة مثلا انا لدي خرج في كل مرة 72 كلمة ولكن تم وصف هذا المقطع ب 20 كلمة 
        # بالتالي اخر 52 كلمة سوف تكون باد
        # الرمز الاخير يعبر عن كلمة غير معروفة اي خارج المفردات 
        # الباقي هو عملية بناء القاموسين
        word2idx = {}
        word2idx['<pad>'] = 0
        word2idx['<bos>'] = 1
        word2idx['<eos>'] = 2
        word2idx['<unk>'] = 3
    
        for idx, w in enumerate(vocab):
            word2idx[w] = idx+4
            idx2word[idx+4] = w
    
        word_counts['<pad>'] = sent_cnt
        word_counts['<bos>'] = sent_cnt
        word_counts['<eos>'] = sent_cnt
        word_counts['<unk>'] = sent_cnt
    
        return word2idx,idx2word
        
        
        
    
    def train(self):
        data = self.get_data() # هنا نحن في تابع التدريب حيث قمنا بالحصول على جميع العبارات ولأي فديو كل عبارة
        self.train_data=[] # قائمة لتخزين الجمل فقط 
        for i in data:
            self.train_data.append(i["caption"])
    # هنا قمنا بتخزين الجمل 
        print(f'Processed train file written to {self.path_prj}/train_val_videodatainfo.json')
        
                

        train_captions = self.train_data
        
    
        captions_list = list(train_captions)  
        captions = np.asarray(captions_list, dtype=np.object) # هنا قمنا بجعلها من نوع نب اري 
    
        captions = list(map(lambda x: x.replace('.', ''), captions))# هنا فقط بعض العمليات مثلا بدل مجل النقطة بفراغ اشارة الاستفهام بفراع وهيك
        captions = list(map(lambda x: x.replace(',', ''), captions))
        captions = list(map(lambda x: x.replace('"', ''), captions))
        captions = list(map(lambda x: x.replace('\n', ''), captions))
        captions = list(map(lambda x: x.replace('?', ''), captions))
        captions = list(map(lambda x: x.replace('!', ''), captions))
        captions = list(map(lambda x: x.replace('\\', ''), captions))
        captions = list(map(lambda x: x.replace('/', ''), captions))
    
        self.word2idx,self.idx2word = self.create_word_dict(captions, word_count_threshold=0) #هنا بتم بناء المفردات والقاموسين من خلال استدعاء التابع  
        
        np.save(self.path_prj / "word2idx",self.word2idx) # هنا يتم حفظ القاموسين 
        np.save(self.path_prj / "idx2word" ,self.idx2word)
        self.n_words = len(self.word2idx) # وحساب عدد المفردات 
    
        tf_loss, tf_video,tf_video_mask,tf_caption,tf_caption_mask, tf_probs,train_op= self.build_model()
        # هنا يتم بناء النموذج من خلال استدعاء التابع 
        sess = tf.compat.v1.InteractiveSession() # هنا يتم بدء جلسة من اجل التنفيذ 
        saver = tf.compat.v1.train.Saver(max_to_keep=5, write_version=1) # هذا الغرض من اجل حفظ المودل 
        
        tf.compat.v1.global_variables_initializer().run()# هذا من اجل تهيئة كل المتحولات 
        
        
    
        loss_out = open('/content/drive/MyDrive/loss.txt', 'w') #هذا ملف نصي من اجل حفظ قيمة الخطأ في كل باتش وفي كل تكرار 
        val_loss = []
    
        for epoch in range(0,self.epochs): # هنا سوف نكرر بعدد التكرارات نحن كررنا 20
            val_loss_epoch = [] 
            current_train_data=self.get_data() # اخذنا بيانات الداتا والتي هي عبارة عن رقم الفديو و وصفة
            '''
            ll = self.get_data()
            ff=list(ll)
            kk=np.linspace(0,140199,140200,dtype=int)
            current_train_data=[]
            for i in kk:
                current_train_data.append(ff[i])
            '''

    # هذه الحلقة من اجل ان نمشي 512 ثم 512 وهكذا اي في كل مرة نأخذ باتش واحد
            for start, end in zip(                   
                    range(0, len(current_train_data),self.batch_size),
                    range(self.batch_size,len(current_train_data)+1,self.batch_size)):
    
                start_time = time.time()  # هذا من اجل حساب الوقت الذي استهلكه كل باتش 
    
                current_batch = current_train_data[start:end] # هنا نأخذ 512 عينة من الداتا
                current_videos=[]# نقوم بتخزين مسارات مصفوفات الفتشرات للفديوهات ال 512
                for v_id in current_batch: # هنا نمر على كل الداتا 512 ونأخذ رقم الفديو وذلك من أجل جلبب مصفوفة الفتشرات له 
                    nn=v_id["video_id"]
                    current_videos.append(r"/content/drive/MyDrive/final_feat"+"/"+str(nn)+".npy")
                 
    
                current_feats = np.zeros((self.batch_size, self.video_lstm_step,self.dim_image))# هنا مصفوفة نقوم فيها بتخزين قيم جميع مصفوفات الفتشرات ال 512
                current_feats_vals = list(map(lambda vid: np.load(vid),current_videos)) # هنا نقوم بتحميل هذه المصفوفات
                current_feats_vals = np.array(current_feats_vals)  # تحويلها ال نب اري
    
                current_video_masks = np.zeros((self.batch_size,self.video_lstm_step))#  هذه نقوم بتخزين واحدات فيها حيث سوف نستخدمها في تقسيم مصفوفة الفديو الى 80 قسم كل قسم لخلية لستم من أجل ان تعالجها
    
                for ind,feat in enumerate(current_feats_vals):
                    current_feats[ind][:len(current_feats_vals[ind])] = feat # هنا نخزن مصفزفات الفتشرات
                    current_video_masks[ind][:len(current_feats_vals[ind])] = 1
    
                current_captions=[]
                for v_caption in current_batch: # هنا نأخذ 512 عينة تدريب ونأخذ جملهم
                    current_captions.append(v_caption["caption"]) # نضعهم في هذه القائمة
                
                current_captions = list(map(lambda x: '<bos> ' + x, current_captions))# نضيف لكل جملة توكن بداية ونهاية الجملة
                current_captions = list(map(lambda x: x.replace('.', ''), current_captions))# وكما ذكرنا نستبدل النقطة بفراغ وهكذا
                current_captions = list(map(lambda x: x.replace(',', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('"', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('\n', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('?', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('!', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('\\', ''), current_captions))
                current_captions = list(map(lambda x: x.replace('/', ''), current_captions))

    
                for idx, each_cap in enumerate(current_captions):
                    word = each_cap.lower().split(' ') # في كل جملة نقوم بوضع كلماتها في قائمة اذا كان طول هذه القائمة اصغر من 72 بالتالي هو نضيف رمز نهاية الجملة الى اخرها وإلا
                    if len(word) < self.caption_lstm_step:
                        current_captions[idx] = current_captions[idx] + ' <eos>'
                    else:
                        new_word = ''
                        for i in range(self.caption_lstm_step-1):
                            new_word = new_word + word[i] + ' '
                        current_captions[idx] = new_word + '<eos>' # هنا يكون طول العبارة 72 بالتالي سوف يتم إضافة توكن نهاية الجملة الى نهاية الجملة 
    
                current_caption_ind = []
                for cap in current_captions:
                    current_word_ind = []
                    for word in cap.lower().split(' '):
                        if word in self.word2idx:
                            current_word_ind.append(self.word2idx[word])# هنا يتم وضع في قائمة دليل كل كلمة موحودة في الجملة من القاموس الذي تعطية الكلمة ويعطيك دليلها 
                        else:
                            current_word_ind.append(self.word2idx['<unk>']) # واذا كانت هذه الكلمة غير موجودة في القاموس نعطيها دليل الرمز غير معروف
                    current_caption_ind.append(current_word_ind) 
    
                current_caption_matrix = sequence.pad_sequences(current_caption_ind, padding='post', maxlen=self.caption_lstm_step)
                # هذه التعليمة من اجل جعل جميع الجمل بطول واحد اي اطول عبارة هي 72 بالتالي كل الجمل يجب ان يكون طولها 72 مثلاً الجملة طولها 20 يكون اول 20 قيم من القاموس و قيمة غير معروف اما بقية القيم  تكون اصفار
                current_caption_matrix = np.hstack( [current_caption_matrix, np.zeros( [len(current_caption_matrix), 1] ) ] ).astype(int)
                #هنا يتم إضافة عمود كله اصفار الى المصفوفة السابقة 
                current_caption_masks = np.zeros( (current_caption_matrix.shape[0], current_caption_matrix.shape[1]) )
                # هنا يتم إنشاء مصفوفة كلها أصفار ببعد المصفوفة السابقة 
                nonzeros = np.array( list(map(lambda x: (x != 0).sum() + 1, current_caption_matrix ) ))
                # هنا يتم عد الأرقام التي لا تساوي الصفر في كل سطر اي نحن نقوم بعد عدد الكلمات في الجملة التي ليست باد
    
                for ind, row in enumerate(current_caption_masks):
                    row[:nonzeros[ind]] = 1  # هنا الكلمات التي ليست باد سوف يتم وضع مكانها 1 اما ال باد سيتم وضع صفر
    
                probs_val = sess.run(tf_probs, feed_dict={
                    tf_video:current_feats,
                    tf_caption: current_caption_matrix
                    })
    # هنا سوف يتم اسناد قيم الثوابت التي تم تعريفها عند بناء النموذج وتنفيذ عملية التدريب 
                _, loss_val = sess.run(
                        [train_op, tf_loss],
                        feed_dict={
                            tf_video: current_feats,
                            tf_video_mask : current_video_masks,
                            tf_caption: current_caption_matrix,
                            tf_caption_mask: current_caption_masks
                            })
                val_loss_epoch.append(loss_val)# هنا يتم حفظ قيمة الخطأ عند كل عملية تحسن 
                total_error=np.sum(val_loss_epoch)/len(val_loss_epoch) # هنا يتم حفظ قيمة الخطأ النهائي لكامل المشروع عند كل تحسين 
                print('Batch starting index: ', start, " Epoch: ", epoch, " loss: ", loss_val," total loss: ",total_error,' Elapsed time: ', str((time.time() - start_time)))
                # هنا يتم صباعة عدد العينات التي تم تدربها ويتم طباعة الخطأ لل 512 عينة التي تم تدربها في هذا التحسين ويتم طباعة الخطأ النهائي حتى لكل العينات السابقة ويتم طباعة الزمن التي احتجناه من اجل تدريب هذه ال 512
                loss_out.write('epoch ' + str(epoch) + ' loss ' + str(loss_val) + '\n') # هنا يتم كتابة قيمة الخطأ لل512 بعد كل عملية تحسن 
            if np.mod(epoch,1) == 0: # هنا يتم حفظ النموذج عند كل تكرار 
                print ("Epoch ", epoch, " is done. Saving the model ...")
                saver.save(sess, os.path.join(self.path_prj, 'model'), global_step=epoch)
    
        loss_out.close() # هنا يتم إغلاق الملف الذي فتحناه للقراءة 
           
            
        
        
        
    
    def inference(self,video_test): # الدخل هنا عبارة عن مسار الفتشرات للفديو الذي نريد اختبارة 
        test_videos=[]
        test_videos.append(video_test)        
        self.idx2word = pd.Series(np.load(self.path_prj / "idx2word.npy",allow_pickle=True).tolist()) # عم نحمل القاموس اللي بحول الرقم ل كلمة 
        
        self.n_words = len(self.idx2word)  # عم ناخذ طول هاد القاموس 
        print(self.n_words)
        video_tf, video_mask_tf, caption_tf, probs_tf, last_embed_tf = self.build_generator() # بنيت النموذج 
    
        sess = tf.compat.v1.InteractiveSession()   # عملت جلسة مشان نفذا بعدين 
    
        saver = tf.compat.v1.train.Saver()  # هاد يلي بدو يرجعلي الاوزان المدربة والانحيازات 
        saver.restore(sess,r"/content/drive/MyDrive/model-19")   # هي التعلمية يلي رح تجيبن للأوزان  
    
        f = open(f'{self.path_prj}/video_captioning_results.txt', 'w')   # هاد الملف هو ملف نصي منكتب فيه بس مسار الفتشرات للفديو يلي منختبروا  و الجملة يلي هي وصفوا
        for idx, video_feat_path in enumerate(test_videos): # هي الحلقة بتاخذ اذا كان في اكتر من فديو المهم اذا كان عند واحد بس اول متحول بياخذ صفر والتاني المسار 
            video_feat = np.load(video_feat_path)[None,...] # هون عم نجيب مصفوفة الفتشرات من المسار السابق وعم تقراها 
            if video_feat.shape[1] == self.frame_step:     # هون عم يختبر اذا البعد الثاني نفسوا يعني هل البعد التاني قيمتوا 80   
                video_mask = np.ones((video_feat.shape[0], video_feat.shape[1])) # عم ينشأ مصفوفة مشان يعبيها عند بناء النموذج 
            else:
                continue
    
            gen_word_idx = sess.run(caption_tf, feed_dict={video_tf:video_feat, video_mask_tf:video_mask})
             # هون بردلك دليل الكلمات 72 يلي النموذج رشحن ليكونوا الترجمة 
            
            gen_words = self.idx2word[gen_word_idx] # هون انت بتحولن لكلمات 
            punct = np.argmax(np.array(gen_words) == '<eos>') + 1 # هون يعد الكلمات يلي قبل عبارة نهاية الجملة وبيسندن ل المتحول هاد 
            
            gen_words = gen_words[:punct] # هون بياخذ قائمة جزئية بعدد هالكلمات من المصفوفة يلي فيها 72 كلمة المرشحة 
            gen_sent = ' '.join(gen_words)   # هون بحول القائمة الى str
            gen_sent = gen_sent.replace('<bos> ', '')# ببدل عبارة بداية ونهاية الجملة بفراغ
            gen_sent = gen_sent.replace(' <eos>', '')
            gen_sent = gen_sent.replace('<unk>', '')
            print(f'Video path {video_feat_path} : Generated Caption \n {gen_sent}')  # بيطبع الترجمة 
            
            f.write(video_feat_path + '\n') 
            f.write(gen_sent + '\n\n')

    def process_main(self):
        if self.mode == 'train':
            self.train()
        else:
            self.inference()

# for testing 
if __name__ == '__main__':
         v=VideoCaptioning(mode="test")
         v.inference(r"/content/drive/MyDrive/features_test/features/video7014.npy")

# fot training
"""
if __name__ == '__main__':
         v=VideoCaptioning()
         v.process_main()
"""